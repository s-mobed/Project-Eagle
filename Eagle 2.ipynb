{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLS-GP-006334\n",
      "2021-09-27 06_10_40 PM BST\n",
      "2021-09-27\n",
      "202109270610\n",
      "2021-09-27 06:10:40 UTC\n"
     ]
    }
   ],
   "source": [
    "## Project Eagle Script by Shean Mobed\n",
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "#MultiFile\n",
    "multifile = sorted(glob('Multifile/*_Genotyping Result_*.csv'))\n",
    "multifile\n",
    "\n",
    "#Concat Files with same cols\n",
    "df = pd.concat((pd.read_csv(file, comment = '#').assign(filename = file)\n",
    "          for file in multifile), ignore_index=True)\n",
    "#Date Extraction\n",
    "File1 = df.filename.get(0)\n",
    "with open (File1) as GenotypingResults:\n",
    "    for line in GenotypingResults:\n",
    "        if line[0:13] == '# Exported On':\n",
    "            date = line[15:41].replace(':','_').replace('\\n','')\n",
    "                    \n",
    "date2 = date[:10]\n",
    "\n",
    "date3 = date[:17].replace('-','').replace(' ','').replace('_','')\n",
    "\n",
    "date4 = date[:19].replace('_',':') + ' UTC'\n",
    "#File name\n",
    "basename = os.path.splitext(os.path.basename(File1))[0]\n",
    "eagle = basename.split('_')[0]\n",
    "print(eagle)\n",
    "print(date)\n",
    "print(date2)\n",
    "print(date3)\n",
    "print(date4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Simplify Table\n",
    "df = df[['Sample','Call','SNP Assay','Confidence']]\n",
    "df['Sample'] = df['Sample'].astype('str')\n",
    "# Remove \n",
    "sample = df['Sample'].str.len() == 11\n",
    "df = df.loc[sample]\n",
    "#Sample0\n",
    "#sample0 = df[(df['Sample'] == '0') | \n",
    "             #(df['Sample'] == 'PosCon') | \n",
    "             #(df['Sample'] == 'NTC') | \n",
    "             #(df['Sample'] == 'PHE') |\n",
    "             #(df['Sample'] == 'Empty')\n",
    "            #]\n",
    "\n",
    "#df = df.drop(sample0.index)\n",
    "\n",
    "\n",
    "#Blank Sample\n",
    "df['Sample'].replace('',np.nan, inplace = True)\n",
    "df.dropna(subset = ['Sample'], inplace = True)\n",
    "\n",
    "#Rename Cols\n",
    "df.rename(columns={'SNP Assay': 'CH1-Target',\n",
    "         'Call': 'CH1-Result',\n",
    "          'Confidence': 'CH1-Conf'},\n",
    "         inplace=True)\n",
    "#Unknown\n",
    "unknown = df.loc[df.Sample.str.contains(\"Unknown\",case=False)]\n",
    "df = df.drop(unknown.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate barcodes :)\n",
      "Check for error in SNP assay column in the files!\n"
     ]
    }
   ],
   "source": [
    "## Duplicates Troubleshooter\n",
    "\n",
    "#Duplicate Barcodes error Raise\n",
    "bcdups = df.groupby(['Sample']).size() > 4\n",
    "bcdups = pd.DataFrame(bcdups)\n",
    "bcdups = bcdups.reset_index()\n",
    "bcdups = bcdups.rename(columns = { 0:'Bool'})\n",
    "bcdups = bcdups[(bcdups['Bool']==True)]\n",
    "bcdups = bcdups.loc[bcdups.Bool == True]\n",
    "\n",
    "#print(bcdups.Sample.count())\n",
    "bcdups.to_csv('dups.csv')\n",
    "\n",
    "try:\n",
    "    if bcdups['Sample'].count() > 0 :\n",
    "        raise Exception\n",
    "except Exception:\n",
    "    print(\"Check for duplicate barcodes in files!, duplicates can be found in dups.csv\")\n",
    "else: print('No duplicate barcodes :)')\n",
    "\n",
    "#SNP assay column duplicates error Raise\n",
    "\n",
    "snpdups = df.groupby(['CH1-Target']).size()\n",
    "snpdups = pd.DataFrame(snpdups)\n",
    "snpdups = snpdups.reset_index()\n",
    "snpdups = snpdups.rename(columns = { 0:'Count'})\n",
    "samplecount = df.index.size / 4\n",
    "\n",
    "try:\n",
    "    if snpdups['Count'][0] > samplecount :\n",
    "        raise Exception\n",
    "except Exception:\n",
    "    print(\"Check for error in SNP assay column in the files!\")\n",
    "else: print('No error found in SNP assay column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Mutation Caller\n",
    "#Duplicate CH1-Result\n",
    "df['CH1-Result-Copy'] = df['CH1-Result']\n",
    "\n",
    "# Fancy Split\n",
    "dfsplit = df['CH1-Result'].str.rsplit('/', n=1)\n",
    "dfsplit2 = dfsplit.str.get(0)\n",
    "dfsplit3 = dfsplit2.replace('.*_wt.*$', 'wt', regex=True).replace('.*_mt.*$','mt', regex=True).replace('.*_mut.*$','mt', regex=True)\n",
    "df['CH1-Result'] = dfsplit3\n",
    "\n",
    "# Fancy Split 2\n",
    "dfsplit = df['CH1-Result-Copy'].str.rsplit('/', n=1)\n",
    "df['CH1-Result-1'] = dfsplit.str.get(0)\n",
    "df['CH1-Result-2'] = dfsplit.str.get(1)\n",
    "RS1 = df['CH1-Result-1'].str.split('_')\n",
    "RS2 = df['CH1-Result-2'].str.split('_')\n",
    "df['CH1-Result-1'] = RS1.str.get(1)\n",
    "df['CH1-Result-2'] = RS2.str.get(1)\n",
    "df['CH1-Split'] = df['CH1-Result-1'] + '_' + df['CH1-Result-2']\n",
    "\n",
    "\n",
    "## Add Cols Date/ Lab ID/ \n",
    "\n",
    "#Date\n",
    "df['Date Tested']= date4\n",
    "#lab ID\n",
    "df['Lab ID']='GLS'\n",
    "#testKit\n",
    "df['testKit']='TaqMan-GT2'\n",
    "\n",
    "#Result Tree\n",
    "Rconds = [\n",
    "    df['CH1-Split'] == 'wt_wt',\n",
    "    (df['CH1-Split'] == 'mt_mt') | (df['CH1-Split'] == 'mut_mut'),\n",
    "    (df['CH1-Split'] == 'wt_mt') | (df['CH1-Split'] == 'mt_wt') | \n",
    "    (df['CH1-Split'] == 'wt_mut') | (df['CH1-Split'] == 'mut_wt') ,\n",
    "    df['CH1-Result'] == 'Undetermined',\n",
    "    df['CH1-Result'] == 'No Amplification',\n",
    "]\n",
    "\n",
    "Rchoices =[\n",
    "    'No Mutation',\n",
    "    'Mutation',\n",
    "    'n/a',# previously 'het'\n",
    "    'n/a',\n",
    "    'n/a',\n",
    "]\n",
    "\n",
    "df['Result'] = np.select(Rconds,Rchoices)\n",
    "\n",
    "#Correct Header Layout\n",
    "dffinal = df[['Sample', 'Result', 'Date Tested', 'Lab ID', 'testKit', 'CH1-Target', 'CH1-Result', 'CH1-Conf']]\n",
    "dffinal = dffinal.sort_values(by = ['Sample','CH1-Target']).set_index('Sample').reset_index()\n",
    "df.columns = df.columns.str.replace(\"'\",\" \")\n",
    "#automatic file name\n",
    "\n",
    "eaglefile = '(' + eagle + ')'\n",
    "\n",
    "labid = 'GLS'\n",
    "\n",
    "#datetested = df['Date Tested'].get(0)\n",
    "\n",
    "spacer = \"_\"\n",
    "\n",
    "endcard1 = '-mut-results.csv'\n",
    "\n",
    "#output to Individual reports\n",
    "outfilename1 = eaglefile + spacer + labid + spacer + date + endcard1\n",
    "outfilepath1 = 'reports/Individual Eagle Reports/'\n",
    "dffinal.to_csv(outfilepath1 + outfilename1, index=False)\n",
    "\n",
    "#output for Jodie\n",
    "outfilename2 = labid + date3 + endcard1\n",
    "outfilepath2 = 'reports/'\n",
    "dffinal.to_csv(outfilepath2 + outfilename2, index=False)\n",
    "\n",
    "#Head\n",
    "#dffinal.tail()\n",
    "#mutsize = dffinal.groupby(['CH1-Target','CH1-Result']).size()\n",
    "#mutsize\n",
    "\n",
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result\n",
       "B.1.617.2    417\n",
       "NA            38\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## VARiants Caller\n",
    "vc = df.pivot_table(index= ['Sample'], columns= 'CH1-Target', values= 'Result', aggfunc=lambda x: ' '.join(x))\n",
    "vc.replace(np.nan, 'n/a', inplace = True)\n",
    "\n",
    "#Lineage Tree\n",
    "wt = 'No Mutation'\n",
    "mt = 'Mutation'\n",
    "het = 'Het'\n",
    "NA = 'n/a'\n",
    "Lconds = [\n",
    "    (vc['P681R'] == wt) & (vc['E484K'] == wt) & (vc['K417N'] == wt) & (vc['K417T'] == wt),\n",
    "    (vc['P681R'] == wt) & (vc['E484K'] == wt) & (vc['K417N'] == wt) & (vc['K417T'] == wt),\n",
    "    (vc['P681R'] == wt) & (vc['E484K'] == mt) & (vc['K417N'] == mt) & (vc['K417T'] != wt),\n",
    "    (vc['P681R'] == wt) & (vc['E484K'] == mt) & (vc['K417N'] != wt) & (vc['K417T'] == mt),\n",
    "    (vc['P681R'] == NA) | (vc['E484K'] == NA) | (vc['K417N'] == NA) | (vc['K417T'] == NA),\n",
    "    (vc['P681R'] == het) | (vc['E484K'] == het) | (vc['K417N'] == het) | (vc['K417T'] == het),\n",
    "    (vc['P681R'] == wt) & (vc['E484K'] == mt) & (vc['K417N'] == wt) & (vc['K417T'] == wt),\n",
    "    (vc['P681R'] == mt) #& (vc['E484K'] != mt) & (vc['K417N'] != mt) & (vc['K417T'] != mt) \n",
    "    \n",
    "  \n",
    "] \n",
    "\n",
    "Lchoices = [\n",
    "    'B.1',\n",
    "    'B.1.1.7',\n",
    "    'B.1.351',\n",
    "    'P.1',\n",
    "    'NA',# previously het\n",
    "    'NA',\n",
    "    'A.23.1',\n",
    "    'B.1.617.2'\n",
    "   \n",
    "]\n",
    "\n",
    "vc['Result'] = np.select(Lconds,Lchoices, default = 'Undetermined')\n",
    "\n",
    "#Format Cols\n",
    "#Date\n",
    "vc['Date Tested'] = date\n",
    "#lab ID\n",
    "vc['Lab ID'] = 'GLS'\n",
    "#testKit\n",
    "vc['testKit'] = df['testKit']\n",
    "#Lineage + Result\n",
    "vc['Result Type'] = 'Lineage'\n",
    "# Second Output Layout\n",
    "vardf = vc[['Result Type', 'Result', 'Date Tested', 'Lab ID']]\n",
    "\n",
    "#automatic file name 2\n",
    "\n",
    "labid = vc['Lab ID'].get(0)\n",
    "\n",
    "datetested = vc['Date Tested'].get(0)\n",
    "\n",
    "spacer = \"_\"\n",
    "\n",
    "endcard2 = 'lineage_report.csv'\n",
    "\n",
    "# Individual report\n",
    "outfilename3 = eaglefile + spacer + labid + spacer + date + spacer + endcard2\n",
    "vardf.to_csv(outfilepath1 + outfilename3, index=True,)\n",
    "\n",
    "#output for Jodie\n",
    "outfilename4 = labid + spacer + date + spacer + endcard2\n",
    "vardf.to_csv(outfilepath2 + outfilename4, index=True)\n",
    "\n",
    "#Head Vardf\n",
    "vardf.head()\n",
    "linsize = vardf.groupby(['Result']).size()\n",
    "linsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Mutation Count File\n",
    "\n",
    "#Mutation Count DF\n",
    "mcdf = df[['CH1-Target', 'CH1-Result']]\n",
    "#Drop No Amp\n",
    "namp = mcdf[(mcdf['CH1-Result'] == 'No Amplification')| (mcdf['CH1-Result'] == 'Undetermined')]\n",
    "mcdf = df.drop(namp.index)\n",
    "#Count Dataframe\n",
    "mcdf = mcdf.groupby(['CH1-Target','CH1-Result']).size().reset_index(name = eagle)\n",
    "mcdf = pd.pivot_table(mcdf,\n",
    "                       index=['CH1-Target','CH1-Result'],\n",
    "                       values= eagle,                            \n",
    "                       fill_value = 0,\n",
    "                       dropna=False)\n",
    "\n",
    "#automatic file name 3\n",
    "\n",
    "endcard3 = 'mutation_count.csv'\n",
    "\n",
    "outfilename5 = labid + spacer + eagle + spacer + endcard3\n",
    "outfilepath3 = 'counts/'\n",
    "mcdf.to_csv(outfilepath3 + outfilename5, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Mutations Summary Report\n",
    "counts = sorted(glob('counts/*mutation_count*.csv'))\n",
    "#Summary Table\n",
    "msdf = pd.concat((pd.read_csv(f, index_col = ['CH1-Result', 'CH1-Target']) \n",
    "                for f in counts), axis =1)\n",
    "msdf = msdf.rename(columns = str.title).sort_index(axis = 1)\n",
    "\n",
    "#Total sum per row: \n",
    "msdf['Total'] = msdf.sum(axis=1)\n",
    "total = 'Total'\n",
    "totalcol = msdf.pop(total)\n",
    "msdf.insert(0,total,totalcol)\n",
    "\n",
    "#automatic file name 4\n",
    "\n",
    "endcard4 = 'eagle_mutation_report_' + date + '.csv'\n",
    "\n",
    "outfilename6 = labid + spacer + endcard4\n",
    "\n",
    "msdf.to_csv(outfilepath3 + outfilename6, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tally Lineage\n",
    "linagg = vc.groupby(['Result'], as_index=True).size().reset_index(name = eagle)\n",
    "namp = linagg[(linagg['Result'] == 'NA')| (linagg['Result'] == 'Undetermined')]\n",
    "linagg = linagg.drop(namp.index)\n",
    "\n",
    "#automatic file name 5\n",
    "\n",
    "endcard5 = 'lineage_count.csv'\n",
    "\n",
    "outfilename7 = labid + spacer + eagle + spacer + endcard5\n",
    "outfilepath4 = 'lineage/'\n",
    "linagg.to_csv(outfilepath4 + outfilename7, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lineage Summary Report\n",
    "#Summary Table\n",
    "lins = sorted(glob('lineage/*lineage_count*.csv'))\n",
    "lsdf = pd.concat((pd.read_csv(f, index_col = ['Result']) \n",
    "                for f in lins), axis =1)\n",
    "\n",
    "lsdf = lsdf.rename(columns = str.title).sort_index(axis = 1)\n",
    "#lsdf = lsdf.rename(columns={'Result': 'Lineage'},inplace=True)\n",
    "\n",
    "#Total sum per row: \n",
    "lsdf['Total'] = lsdf.sum(axis=1)\n",
    "total = 'Total'\n",
    "totalcol = lsdf.pop(total)\n",
    "lsdf.insert(0,total,totalcol)\n",
    "lsdf = lsdf.fillna(0).astype(int)\n",
    "\n",
    "#automatic file name 6\n",
    "\n",
    "endcard6 = 'eagle_lineage_report_' + date + '.csv'\n",
    "\n",
    "outfilename8 = labid + spacer + endcard6\n",
    "\n",
    "lsdf.to_csv(outfilepath4 + outfilename8, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tally Combos\n",
    "cdf = df[['Sample','CH1-Target','CH1-Split']]\n",
    "cdf = cdf.replace(np.nan,'N/A')\n",
    "cdf = cdf.reset_index(drop=True)\n",
    "\n",
    "#Changing mut to mt\n",
    "cdf['CH1-Split'] = cdf['CH1-Split'].replace('mut_mut','mt_mt')\n",
    "\n",
    "#Pivot Table\n",
    "cdf = cdf.pivot(index = ['Sample'], columns = 'CH1-Target')\n",
    "\n",
    "#Sample Count Row\n",
    "samplecount = cdf.index.size\n",
    "samplecountdf = pd.DataFrame({'Combo': 'Total', date2 : samplecount}, index = [0])\n",
    "\n",
    "#Dropping MultiIndex\n",
    "cdf.columns = ['_'.join(col) for col in cdf.columns.values]\n",
    "cdf.rename(columns={'CH1-Split_E484K': 'E484K',\n",
    "                   'CH1-Split_K417N': 'K417N',\n",
    "                   'CH1-Split_K417T': 'K417T',\n",
    "                   'CH1-Split_P681R': 'P681R'},\n",
    "         inplace=True)\n",
    "\n",
    "#cdf = cdf.reset_index(drop=True)\n",
    "\n",
    "# Removing Wildtypes and N/a / Defining Heterogenous Mutants\n",
    "het = ('wt_mut' , 'mut_wt' , 'wt_mt' , 'mt_wt')\n",
    "cdf = cdf.replace(het,'').replace('wt_wt', '').replace('N/A', '')\n",
    "cdf = cdf.dropna()\n",
    "\n",
    "# Substituting mutant calls for their names\n",
    "\n",
    "cdf.loc[(cdf.E484K == 'mt_mt'),['E484K']] = 'E484K'\n",
    "cdf.loc[(cdf.K417T == 'mt_mt'),['K417T']] = 'K417T'\n",
    "cdf.loc[(cdf.K417N == 'mt_mt'),['K417N']] = 'K417N'\n",
    "cdf.loc[(cdf.P681R == 'mt_mt'),['P681R']] = 'P681R'\n",
    "\n",
    "\n",
    "# Naming Het Combos\n",
    "#cdf.loc[(cdf.N501Y == 'Het'),['N501Y']] = 'N501Y (Het)'\n",
    "#cdf.loc[(cdf.E484K == 'Het'),['E484K']] = 'E484K (Het)'\n",
    "#cdf.loc[(cdf.K417T == 'Het'),['K417T']] = 'K417T (Het)'\n",
    "#cdf.loc[(cdf.K417N == 'Het'),['K417N']] = 'K417N (Het)'\n",
    "\n",
    "# Joining mutant call columns into one result column\n",
    "cdf['Combo'] = cdf[['E484K', 'K417N','K417T','P681R']].agg('+'.join, axis=1)\n",
    "#Stripping excess '+' separators\n",
    "cdf['Combo'] = cdf['Combo'].str.strip('+')\n",
    "cdf['Combo'] = cdf['Combo'].str.replace('\\++', '+', regex=True)\n",
    "cdf['Combo'] = cdf['Combo'].replace('',np.nan)\n",
    "\n",
    "# Counting mutation combos\n",
    "combo = cdf.groupby(['Combo']).size().reset_index(name = date2)\n",
    "combo = pd.concat([samplecountdf, combo[:]]).reset_index(drop = True)\n",
    "\n",
    "#automatic file name \n",
    "labid ='GLS'\n",
    "spacer = \"_\"\n",
    "endcard7 = 'combo.csv'\n",
    "outfilename9 = labid + spacer + date2 + spacer + endcard7\n",
    "outfilepath5 = 'Combo/'\n",
    "combo.to_csv(outfilepath5 + outfilename9, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combo Summary Report\n",
    "#Summary Table\n",
    "combos = sorted(glob('Combo/*combo*.csv'))\n",
    "csdf = pd.concat((pd.read_csv(f, index_col = ['Combo']) \n",
    "                for f in combos), axis = 1)\n",
    "\n",
    "#Total sum per row: \n",
    "csdf['Total'] = csdf.sum(axis=1)\n",
    "total = 'Total'\n",
    "totalcol = csdf.pop(total)\n",
    "csdf.insert(0,total,totalcol)\n",
    "\n",
    "#Custom Index\n",
    "ComboIndex = ['Total','N501Y','E484K','E484K+N501Y',\n",
    "              'K417N','E484K+K417N','K417N+N501Y','E484K+K417N+N501Y',\n",
    "              'K417T','E484K+K417T+N501Y','P681R']\n",
    "csdf = csdf.reindex(ComboIndex)\n",
    "csdf = csdf.fillna(0).astype(int)\n",
    "\n",
    "#automatic file name 2\n",
    "\n",
    "endcard8 = 'combination_report_' + date2 + '.csv'\n",
    "\n",
    "outfilename10 = labid + spacer + endcard8\n",
    "\n",
    "csdf.to_csv(outfilepath5 + outfilename10, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
